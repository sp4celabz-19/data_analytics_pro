{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28fdbbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥ –ø–æ –∑–∞–ø—Ä–æ—Å—É 'detective': 1000000\n",
      "üì• startIndex=0, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=40, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=80, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=120, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=160, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=200, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=240, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=280, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=320, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 0\n",
      "üö´ –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: 320 –∫–Ω–∏–≥\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ 320 –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª 'books_detective.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_books(query, max_total=1000, delay=0.2):\n",
    "    all_books = []\n",
    "    max_results = 40\n",
    "\n",
    "    for start_index in range(0, max_total, max_results):\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'startIndex': start_index,\n",
    "            'maxResults': max_results,\n",
    "        }\n",
    "        response = requests.get('https://www.googleapis.com/books/v1/volumes', params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–Ω–∏–≥ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ\n",
    "        if start_index == 0:\n",
    "            total = data.get('totalItems', '?')\n",
    "            print(f\"üîé –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}': {total}\")\n",
    "\n",
    "        items = data.get('items', [])\n",
    "        print(f\"üì• startIndex={start_index}, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: {len(items)}\")\n",
    "\n",
    "        if not items:\n",
    "            print(\"üö´ –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.\")\n",
    "            break\n",
    "\n",
    "        for item in items:\n",
    "            info = item.get('volumeInfo', {})\n",
    "            all_books.append({\n",
    "                'title': info.get('title'),\n",
    "                'authors': ', '.join(info.get('authors', [])),\n",
    "                'publishedDate': info.get('publishedDate'),\n",
    "                'categories': ', '.join(info.get('categories', [])) if 'categories' in info else None,\n",
    "                'pageCount': info.get('pageCount'),\n",
    "                'averageRating': info.get('averageRating'),\n",
    "                'ratingsCount': info.get('ratingsCount'),\n",
    "                'description': info.get('description')\n",
    "            })\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: {len(all_books)} –∫–Ω–∏–≥\\n\")\n",
    "    return pd.DataFrame(all_books)\n",
    "\n",
    "# üîç –ó–∞–ø—Ä–æ—Å\n",
    "query = \"detective\"\n",
    "df = fetch_books(query, max_total=1000)\n",
    "\n",
    "# üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "filename = f\"books_{query.replace(' ', '_')}.csv\"\n",
    "df.to_csv(filename, index=False, encoding='utf-8')\n",
    "print(f\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª '{filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d2b7457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>categories</th>\n",
       "      <th>pageCount</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clown Horror (Russian Edition)</td>\n",
       "      <td>I. D. Oro</td>\n",
       "      <td>None</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>433.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç F√ºhrer Devil-Eggs –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ—Ç—Å—è –∫ –õ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clown Horror 152 (Russian Edition)</td>\n",
       "      <td>I. D. Oro</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>132.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Osvaldo –≥–µ–Ω–∏–π, –¥–∞–∂–µ –µ—Å–ª–∏ –µ–≥–æ –∂–µ–Ω–∞ Sariyah –ª—é–±–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clown Horror 150 (Russian Edition)</td>\n",
       "      <td>I. D. Oro</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–í –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏—è ¬´–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horror Fiction</td>\n",
       "      <td>Gina Wisker</td>\n",
       "      <td>2005-07-13</td>\n",
       "      <td>Literary Criticism</td>\n",
       "      <td>308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is a series of introductory books about d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Presenting Young Adult Horror Fiction</td>\n",
       "      <td>Cosette N. Kies</td>\n",
       "      <td>1992</td>\n",
       "      <td>American fiction</td>\n",
       "      <td>232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horror, an increasingly popular subject for bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title          authors publishedDate  \\\n",
       "0         Clown Horror (Russian Edition)        I. D. Oro          None   \n",
       "1     Clown Horror 152 (Russian Edition)        I. D. Oro    2022-01-02   \n",
       "2     Clown Horror 150 (Russian Edition)        I. D. Oro    2022-01-02   \n",
       "3                         Horror Fiction      Gina Wisker    2005-07-13   \n",
       "4  Presenting Young Adult Horror Fiction  Cosette N. Kies          1992   \n",
       "\n",
       "            categories  pageCount  averageRating  ratingsCount  \\\n",
       "0  Young Adult Fiction      433.0            NaN           NaN   \n",
       "1  Young Adult Fiction      132.0            NaN           NaN   \n",
       "2  Young Adult Fiction      133.0            NaN           NaN   \n",
       "3   Literary Criticism      308.0            NaN           NaN   \n",
       "4     American fiction      232.0            NaN           NaN   \n",
       "\n",
       "                                         description  \n",
       "0  –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç F√ºhrer Devil-Eggs –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ—Ç—Å—è –∫ –õ...  \n",
       "1  Osvaldo –≥–µ–Ω–∏–π, –¥–∞–∂–µ –µ—Å–ª–∏ –µ–≥–æ –∂–µ–Ω–∞ Sariyah –ª—é–±–∏...  \n",
       "2  –í –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏—è ¬´–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ...  \n",
       "3  This is a series of introductory books about d...  \n",
       "4  Horror, an increasingly popular subject for bo...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82e81466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥ –ø–æ –∑–∞–ø—Ä–æ—Å—É 'detective AND author:Agatha': 1000000\n",
      "üì• startIndex=0, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=40, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=80, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=120, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=160, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=200, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=240, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 0\n",
      "üö´ –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: 240 –∫–Ω–∏–≥\n",
      "\n",
      "üîé –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥ –ø–æ –∑–∞–ø—Ä–æ—Å—É 'detective AND author:Doyle': 1000000\n",
      "üì• startIndex=0, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=40, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=80, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=120, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=160, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=200, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=240, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=280, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=320, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 0\n",
      "üö´ –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: 320 –∫–Ω–∏–≥\n",
      "\n",
      "üîé –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥ –ø–æ –∑–∞–ø—Ä–æ—Å—É 'detective AND thriller': 1000000\n",
      "üì• startIndex=0, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=40, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=80, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=120, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=160, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=200, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=240, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=280, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=320, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 0\n",
      "üö´ –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: 320 –∫–Ω–∏–≥\n",
      "\n",
      "üîé –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥ –ø–æ –∑–∞–ø—Ä–æ—Å—É 'detective AND mystery': 1000000\n",
      "üì• startIndex=0, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=40, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=80, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=120, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=160, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=200, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=240, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=280, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 40\n",
      "üì• startIndex=320, –ø–æ–ª—É—á–µ–Ω–æ –∫–Ω–∏–≥: 0\n",
      "üö´ –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Å–µ–≥–æ: 320 –∫–Ω–∏–≥\n",
      "\n",
      "‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç 1068 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–Ω–∏–≥.\n"
     ]
    }
   ],
   "source": [
    "all_queries = [\n",
    "    \"detective AND author:Agatha\",\n",
    "    \"detective AND author:Doyle\",\n",
    "    \"detective AND thriller\",\n",
    "    \"detective AND mystery\"\n",
    "]\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for q in all_queries:\n",
    "    df = fetch_books(q, max_total=1000)\n",
    "    df['query'] = q  # —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –ø–æ–Ω–∏–º–∞—Ç—å, –æ—Ç–∫—É–¥–∞ –∫–Ω–∏–≥–∞\n",
    "    all_dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df.drop_duplicates(subset=[\"title\", \"authors\"], inplace=True)\n",
    "\n",
    "combined_df.to_csv(\"books_detective_expanded.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç {len(combined_df)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–Ω–∏–≥.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecf708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>categories</th>\n",
       "      <th>pageCount</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Science-fiction</td>\n",
       "      <td>Everett Franklin Bleiler, Richard Bleiler</td>\n",
       "      <td>1998</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complementing Science-Fiction: The Early Years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Science/Fiction Collections</td>\n",
       "      <td>Lee Ash</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science/Fiction Collections offers different v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>Roger Luckhurst</td>\n",
       "      <td>2005-05-06</td>\n",
       "      <td>Language Arts &amp; Disciplines</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this new and timely cultural history of sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Science Fiction Film</td>\n",
       "      <td>Keith M. Johnston</td>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>Performing Arts</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science Fiction Film develops a historical and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science Fiction Criticism</td>\n",
       "      <td>Rob Latham</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>Literary Criticism</td>\n",
       "      <td>593.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Including more than 30 essential works of scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title                                    authors  \\\n",
       "0              Science-fiction  Everett Franklin Bleiler, Richard Bleiler   \n",
       "1  Science/Fiction Collections                                    Lee Ash   \n",
       "2              Science Fiction                            Roger Luckhurst   \n",
       "3         Science Fiction Film                          Keith M. Johnston   \n",
       "4    Science Fiction Criticism                                 Rob Latham   \n",
       "\n",
       "  publishedDate                   categories  pageCount  averageRating  \\\n",
       "0          1998                      Fiction      780.0            NaN   \n",
       "1    2013-08-21                      Fiction      190.0            NaN   \n",
       "2    2005-05-06  Language Arts & Disciplines      320.0            NaN   \n",
       "3    2013-05-09              Performing Arts      193.0            NaN   \n",
       "4    2017-02-23           Literary Criticism      593.0            NaN   \n",
       "\n",
       "   ratingsCount                                        description  \n",
       "0           NaN  Complementing Science-Fiction: The Early Years...  \n",
       "1           NaN  Science/Fiction Collections offers different v...  \n",
       "2           NaN  In this new and timely cultural history of sci...  \n",
       "3           NaN  Science Fiction Film develops a historical and...  \n",
       "4           NaN  Including more than 30 essential works of scie...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # columns = [\n",
    "# #     \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "# #     \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "# #     \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"salary\"\n",
    "# # ]\n",
    "\n",
    "# data = pd.read_csv('books_science_fiction.csv')\n",
    "\n",
    "# # data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
